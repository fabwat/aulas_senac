{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso 02 - CERN\n",
    "\n",
    "## Desvendando os segredos do universo com Big Data\n",
    "\n",
    "### (Baseado no livro Big Data in Practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/big-data-in-practice.jpg\" width=150 align=\"center\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<img src=\"img/big-data-in-practice.jpg\" width=150 align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contexto\n",
    "\n",
    "* A Organização Europeia para a Pesquisa Nuclear, conhecida como CERN (antigo, *Conseil Européen pour la Recherche Nucléaire*)\n",
    "\n",
    "\n",
    "* Opera o Large Hadron Collider (LHC)\n",
    "\n",
    "\n",
    "* O maior e mais avançado experimento de física da humanidade, que visa simular as condições no milissegundo do Big Bang\n",
    "\n",
    "\n",
    "* Permite que os físicos procurem partículas teóricas elusivas, como o bosón de Higgs, que pode nos dar uma visão sem precendentes sobre a composição do universo\n",
    "\n",
    "\n",
    "* Os projetos do CERN, como o LHC, não seriam possíveis se não fosse pela Internet e Big Data - de fato, a Internet foi originalmente criada no CERN na década de 1990. Tim Berners-Lee, o homem muitas vezes referido como o \"pai da web\", desenvolveu o protocolo de hipertexto que une a World Wide Web, enquanto no CERN. Seu objetivo original era facilitar a comunicação entre pesquisadores de todo o mundo. \n",
    "\n",
    "\n",
    "* Só o LHC gera cerca de 30 petabytes de informação por ano - 15 milhões de páginas de texto impresso - ou 600 milhões de armários"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que Problema é Resolvido com a Ajuda de Big Data?\n",
    "\n",
    "* As colisões monitoradas no LHC acontecem muito rapidamente, e os \"detritos\" subatômicos resultantes, contendo as partículas procuradas e evasivas, existem por apenas alguns milionésimos de segundo antes de decairem\n",
    "\n",
    "\n",
    "* As condições exatas que causam a liberação das partículas que o CERN está procurando só ocorrem sob condições muito precisas e, como resultado, muitas centenas de milhões de colisões têm que ser monitoradas e registradas a cada segundo, na esperança de que os sensores as capturem\n",
    "\n",
    "\n",
    "* Os sensores do LHC registram centenas de milhões de colisões entre partículas, algumas das quais atingem velocidades de apenas uma fração sob a velocidade da luz à medida que são aceleradas em torno do acelerador \n",
    "\n",
    "\n",
    "* Isso gera uma enorme quantidade de dados e exige equipamentos muito sensíveis e precisos para medir e registrar os resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Como o Big Data é Utilizado na Prática?\n",
    "\n",
    "* O LHC é usado para procurar por partículas teórica envolvendo antimatéria, matéria escura e dimensões extras no tempo e no espaço, além de outras coisas\n",
    "\n",
    "\n",
    "* Os dados são coletados por sensores dentro do colisor que monitoram centenas de milhões de colisões de partículas a cada segundo. Os sensores, que são essencialmente câmeras, captam a luz com uma resolução de 100 megapixels. \n",
    "\n",
    "\n",
    "* Estes dados são então analisados por algoritmos, que captam as assinaturas de energia deixadas pelo aparecimento e desaparecimento das partículas-alvo. Os algoritmos comparam as imagens resultantes com dados teóricos que explicam como acreditamos que as partículas-alvo, como o bóson de Higgs, atuarão. Se os resultados coincidirem, é prova de que os sensores encontraram as partículas-alvo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quais foram os Resultados?\n",
    "\n",
    "* Em 2013, os cientistas do CERN anunciaram que acreditavam ter observado e registrado a existência do bóson de Higgs. Este foi um grande salto para a ciência, já que a existência da partícula havia sido teorizada por décadas, mas não pôde ser provada até que a tecnologia fosse desenvolvida nessa escala. A descoberta deu aos cientistas uma visão sem precedentes sobre a estrutura fundamental do universo e as complexas relações entre as partículas fundamentais com as quais tudo o que vemos, experimentamos e interagimos é construído. \n",
    "\n",
    "\n",
    "* Além do LHC, o CERN existe desde a década de 1950 e tem sido responsável por muitos avanços científicos em experimentos anteriores, e muitos cientistas de renome mundial fizeram seu nome através de seu trabalho com a organização."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Que Dados foram Utilizados?\n",
    "\n",
    "* O LHC reúne dados usando sensores de luz para registrar a colisão e a precipitação de prótons acelerados a 99,9% da velocidade da luz. \n",
    "\n",
    "\n",
    "* Sensores dentro dos coletores captam a energia da luz emitida durante as colisões e a partir da decomposição das partículas resultantes, e a convertem em dados que podem ser analisados por algoritmos de computador. \n",
    "\n",
    "\n",
    "* Muitos desses dados, essencialmente fotografias, não são estruturados. Algoritmos transformam padrões de luz registrados pelos sensores em dados matemáticos. Dados teóricos - idéias sobre como achamos que as partículas que estão sendo caçadas irão atuar - são comparadas com os dados do sensor para determinar o que foi capturado na câmera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quais são os Detalhes Técnicos?\n",
    "\n",
    "* A Worldwide LHC Computing Grid é a maior rede de computação distribuída do mundo, abrangendo 170 centros de computação em 35 países diferentes. \n",
    "\n",
    "\n",
    "* Para desenvolver sistemas distribuídos capazes de analisar 30 petabytes de informação por ano, o CERN promoveu o projeto openlab, em colaboração com especialistas em dados de empresas como Oracle, Intel e Siemens. \n",
    "\n",
    "\n",
    "* A rede consiste em mais de 200.000 núcleos e 15 petabytes de espaço em disco. Os 300 gigabytes por segundo de dados fornecidos pelos sete sensores do CERN acabam sendo reduzidos a 300 megabytes por segundo de dados \"úteis\", o que constitui a saída bruta do produto. \n",
    "\n",
    "\n",
    "* Esses dados são disponibilizadoso em tempo real para instituições acadêmicas em parceria com o CERN. O CERN desenvolveu métodos para aumentar a capacidade de computação em tempo real para aumentar a saída de processamento da rede sem colocá-la offline, em tempos de aumento na demanda por energia computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quais Desafios Tiveram que ser Superados?\n",
    "\n",
    "\n",
    "* Nenhuma organização na Terra tem o poder computacional e os recursos necessários para analisar esses dados em tempo hábil. Para lidar com isso, o CERN voltou-se para a computação distribuída. Eles já estavam usando computação distribuída há algum tempo. De fato, a Internet como a conhecemos hoje foi inicialmente construída para salvar os cientistas de terem que viajar para Genebra sempre que quisessem analisar os resultados das experiências anteriores do CERN. \n",
    "\n",
    "\n",
    "* Para o LHC, o CERN criou o Grid Computing Distributed LHC, que compreende 170 centros de computação em 35 países. Muitos deles são centros de computação privada operados pelas organizações acadêmicas e comerciais em parceria com o CERN. Esse uso paralelo e distribuído do poder de processamento do computador significa que muito mais cálculos por segundo podem ser realizados do que até mesmo os supercomputadores mais poderosos do mundo poderiam gerenciar sozinhos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quais são as Principais Lições Aprendidas?\n",
    "\n",
    "O trabalho inovador realizado pelo CERN, que melhorou muito nosso conhecimento de como o universo funciona, não seria possível sem Big Data e analytics. O CERN e o Big Data evoluíram juntos: o CERN foi um dos principais catalisadores no desenvolvimento da Internet, o que trouxe a era do Big Data em que vivemos hoje. A computação distribuída possibilita a execução de tarefas que estão muito além das capacidades de qualquer organização para serem concluídas sozinhas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leituras Adicionais\n",
    "\n",
    "1. Purcell, A. (2013) CERN on preparing for tomorrow's big data, http://home.web.cern.ch/about/updates/2013/10/preparing-tomorrows-big-data\n",
    "\n",
    "\n",
    "2. Darrow, B. (2013) Attacking CERN's big data problem, https://gigaom.com/2013/09/18/attacking-cerns-big-data-problem/\n",
    "\n",
    "\n",
    "3. O'Luanaigh, C. (2013) Exploration on the big data frontier, http://home.web.cern.ch/students-educators/updates/2013/05/exploration-big-datafrontier\n",
    "\n",
    "\n",
    "4. Smith, T. (2015) Video on CERN's big data, https://www.youtube.com/watch?v=j-0cUmUyb-Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
