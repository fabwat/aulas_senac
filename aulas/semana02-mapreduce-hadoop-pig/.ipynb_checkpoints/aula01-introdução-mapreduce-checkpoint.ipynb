{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introdução ao MapReduce\n",
    "\n",
    "\n",
    "## MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# O que é o MapReduce?\n",
    "\n",
    "\n",
    "Map Reduce é um modelo de programação que processa e analisa grandes quantidades de dados logicamente em clusters separados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Principais Componentes do Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"img/hadoop-core-components.jpg\" width=\"100%\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<img src=\"img/hadoop-core-components.jpg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### O Processamento de dados utilizando MapReduce\n",
    "\n",
    "\n",
    "#### MapReduce\n",
    "\n",
    "##### É a componente de processamento do Apache Hadoop\n",
    "\n",
    "\n",
    "##### Processa os dados paralelamente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### MapReduce na Essência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<img src=\"img/mapreduce-in-a-nutshell.jpg\" width=\"100%\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "\n",
    "<img src=\"img/mapreduce-in-a-nutshell.jpg\" width=\"100%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Principais Vantagens e Características do MapReduce\n",
    "\n",
    "#### Dados processados em paralelo\n",
    "\n",
    "#### Processamento rápido\n",
    "\n",
    "#### Mover dados para processamento se torna muito caro (i.e., custoso em termos de tempo, largura de banda entre outros)\n",
    "\n",
    "#### No MapReduce, movemos o processamento para os dados\n",
    "\n",
    "<img src=\"img/distributed-computing.jpg\" width=\"20%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemplos\n",
    "\n",
    "\n",
    "## Como contar quantas espadas há em um baralho de cartas?\n",
    "\n",
    "\n",
    "### Dividir o baralho entre todos os jogadores da mesa\n",
    "\n",
    "\n",
    "### Dizer a todos os jogadores que devem contar as espadas em seus baralhos e reportar o número de volta para você\n",
    "\n",
    "\n",
    "### Você deve somar todas as somas parciais de todos os jogadores para chegar a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MapReduce Building Blocks\n",
    "\n",
    "\n",
    "1. Consiste de duas fases, o mapeamento (map) e o redução (reduce)\n",
    "\n",
    "\n",
    "2. Ambas as fases recebem a entrada em um formato de chave-valor e emitem dados como chave-valor\n",
    "\n",
    "\n",
    "3. Quando os maps terminam de executar, os reducers rodam em paralelo nos nós (reducers não necessitam esperar todos os mappers terminarem de executar\n",
    "\n",
    "\n",
    "<img src=\"http://ercoppa.github.io/HadoopInternals/public/images/timeline-mapreduce-job_534c0041-2498-44cd-9480-18910a008c0f.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MapReduce Building Blocks (cont.)\n",
    "\n",
    "\n",
    "4. Geralmente, o conjunto de dados é tão grande que uma única instância de map e reduce não são sucificientes para processarem todo o conjunto.\n",
    "\n",
    "\n",
    "5. Tipicamente, temos M x N instâncias de mapper e reducers respectivamente envolvido no processamento dos dados (M > N)\n",
    "\n",
    "\n",
    "6. Os programas mappers rodam em paralelo nos DataNodes\n",
    "\n",
    "\n",
    "7. O MapReduce resolve a maioria dos problemas de análise relacionados ao big data ao espalhar a computação pelos nós de um cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Classe Mapper\n",
    "\n",
    "\n",
    "1. Mapeia entradas de pares chave-valor para pares chave-valor intermediários\n",
    "\n",
    "\n",
    "2. Sort - aplica a classificação de entradas de chaves\n",
    "\n",
    "\n",
    "3. Shuffle e Sort acontecem simultaneamente enquanto fazem a entrada de dados\n",
    "\n",
    "\n",
    "4. Reduce - chama a função reduce para cada chave, coleção de valores\n",
    "\n",
    "\n",
    "5. Saída do reduce é escrita em `RecordWriter` via objeto de contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A Contagem de Palavras no MapReduce\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Oscar_Pereira3/publication/270448794/figure/fig6/AS:295098651824130@1447368409317/Word-count-program-flow-executed-with-MapReduce-5.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Combiner\n",
    "\n",
    "\n",
    "1. Papel primário é otimizar/minimizar o número de chaves-valores espalhados pelo cluster\n",
    "\n",
    "\n",
    "2. Reduz os dados intermediários e escrita no disco\n",
    "\n",
    "\n",
    "3. Reduz os dados trafegados pela rede\n",
    "\n",
    "\n",
    "4. O Combiner é representado pela mesma interface do Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Combiner (cont)\n",
    "\n",
    "\n",
    "<img src=\"https://image.slidesharecdn.com/module3-bigdataandhadoop-160425063358/95/hadoop-mapreduce-framework-48-638.jpg?cb=1461743943\" width=\"100%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Escrevendo o Mapper\n",
    "\n",
    "| id do usuário | id do filme | classificação | timestamp |\n",
    "|--------------:|------------:|:-------------:|:---------:|\n",
    "| 196           | 242         | 3             | 123456789 |\n",
    "| 186           | 302         | 3             | 123456789 |\n",
    "| 196           | 377         | 1             | 123456789 |\n",
    "| 244           | 51          | 2             | 123456789 |\n",
    "| 166           | 346         | 1             | 123456789 |\n",
    "| 186           | 474         | 4             | 123456789 |\n",
    "| 186           | 265         | 2             | 123456789 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def mapper_get_ratings(self, _, line):\n",
    "    (userID, movieID, rating, timestamp) = line.split('\\t')\n",
    "    yield rating,1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# => Map\n",
    "\n",
    "| Results |\n",
    "|-----|\n",
    "| 3,1 |\n",
    "| 3,1 |\n",
    "| 1,1 |\n",
    "| 2,1 |\n",
    "| 1,1 |\n",
    "| 4,1 |\n",
    "| 2,1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# => Shuffle & Sort\n",
    "\n",
    "\n",
    "| Results  |\n",
    "|----------|\n",
    "| 1 -> 1,1 |\n",
    "| 2 -> 1,1 |\n",
    "| 3 -> 1,1 |\n",
    "| 4 -> 1   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# => Reduce\n",
    "\n",
    "\n",
    "| Results  |\n",
    "|----------|\n",
    "| 1,2      |\n",
    "| 2,2      |\n",
    "| 3,2      |\n",
    "| 4,1      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def reducer_count_ratings(self, key, values):\n",
    "    yield key, sum(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tudo Junto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "\n",
    "class RatingsBreakdown(MRJob):\n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper=self.mapper_get_ratings,\n",
    "                   reducer=self.reducer_count_ratings)\n",
    "        ]\n",
    "    \n",
    "    def mapper_get_ratings(self, _, line):\n",
    "        (userID, movieID, ratings, timestamp) = line.split(\"\\t\")\n",
    "        yield rating,1\n",
    "        \n",
    "    def reducer_count_ratings(self, key, values):\n",
    "        yield key, sum(values)\n",
    "\n",
    "if (__name__ == '__main__'):\n",
    "    RatingsBreakdown.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Quantas Tarefas Map?\n",
    "\n",
    "```\n",
    "num_splits = 0\n",
    "for each input file f:\n",
    "   remaining = f.length\n",
    "   while remaining / split_size > split_slope:\n",
    "      num_splits += 1\n",
    "      remaining -= split_size\n",
    "```\n",
    "\n",
    "em que:\n",
    "\n",
    "```\n",
    "split_slope = 1.1\n",
    "split_size =~ dfs.blocksize\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Animação MapReduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fIECbEKyWNQ\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>')"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/fIECbEKyWNQ\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
