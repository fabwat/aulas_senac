{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P01: Introdução ao Spark com Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Criação de RDD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estrutura de dados mais fundamental do Spark é o `conjunto de dados distribuídos resiliente` (em inglês, essa estrutura de dados é conhecida como *Resilient Distributed Dataset* ou RDD). Um RDD é uma coleção distribuída de elementos.\n",
    "\n",
    "Toda tarefa no Spark trata de criar novas RDDs, transformar RDDs existentes, ou invocar RDDs para computar algum resultado. O Spark automaticamente distribui os dados contidos em uma RDD em clusters e computa as operações em paralelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos utilizar o conjunto de dados da copa KDD de 1999 é descrito em detalhes [aqui](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como obter o `SparkContext`\n",
    "\n",
    "O `SparkContext` Carregado automaticamente quando o notebook é iniciado pelo PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Somente necessário quando o notebook não é carregado pelo PySpark\n",
    "#import pyspark\n",
    "#sc = pyspark.SparkContext(appName=\"P1\")\n",
    "\n",
    "# Quando o notebook é carregado pelo PySpark, a variável sc é disponibilizada automaticamente\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo o conjunto de dados de análise reduzido\n",
    "\n",
    "Usaremos um conjunto reduzido de dados (10%) da Copa KDD de 1999, que contém quase meio milhão de registros. O arquivo é fornecido como um *Gzip*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as request\n",
    "f = request.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\", \"kddcup.data_10_percent.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atenção! Lembre-se de colocar o arquivo baixado no `HDFS`. Além disso, inicie o `HDFS` e o `Yarn`.\n",
    "\n",
    "```bash\n",
    "start-dfs.sh\n",
    "start-yarn.sh\n",
    "hdfs dfs -put kddcup.data_10_percent.gz /usr/hduser\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando um RDD a partir de um arquivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma comum de criar um RDD é carregá-lo de um arquivo. \n",
    "\n",
    "\n",
    "Veja que a função `textFile` lida diretamente com arquivos comprimidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_arquivo = \"./kddcup.data_10_percent.gz\"\n",
    "rdd = sc.textFile(nome_arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora temos nosso arquivo de dados carregados em um RDD chamado `dados_brutos`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A coisa mais básica que podemos fazer para checar que o conteúdo do RDD está certo é contar o número de linhas carregadas em nosso RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos também checar as primeiras entradas em nossos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos próximos notebooks, vamos usar estes dados brutos para aprender sobre as diferentes transformações e ações que o Spark pode fazer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando um RDD usando `parallelize`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma forma de criar um RDD é parelelizar uma lista existente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = range(100)\n",
    "\n",
    "rdd2 = sc.parallelize(lista)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como feito anteriormente, podemos `count()` o número de elementos em um RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como anteriormente, podemos acessar os primeiros elementos em nosso RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2.take(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
