{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao Spark com Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDD: `sample` e `takeSample`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como obter o `SparkContext`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.15.17:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>P3</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=P3>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext(appName=\"P3\")\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtendo o conjunto de dados de análise completo\n",
    "\n",
    "Usaremos um conjunto dados completo da Copa KDD de 1999, que contém quase meio milhão de registros. O arquivo é fornecido como um *Gzip*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as request\n",
    "f = request.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz\", \"kddcup.data.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos este arquivos para criar nosso RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nome_arquivo = \"./kddcup.data.gz\"\n",
    "rdd = sc.textFile(nome_arquivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amostrando RDDs   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Spark, existem duas operações de amostragem: a transformação `sample` e a ação `takeSample`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A transformação `sample`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A transformação `sample` aceita até 3 parâmetros. O primeiro trata de informar se a amostragem é feita com substituição ou não. O segundo é o tamanho da amostra como fração. O último parâmetro informa um *random seed*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O tamanho da amostra é 489957 de 4898431\n"
     ]
    }
   ],
   "source": [
    "amostra_rdd = rdd.sample(False, 0.1, 1234)\n",
    "tamanho_amostra = amostra_rdd.count()\n",
    "tamanho_total = rdd.count()\n",
    "print(\"O tamanho da amostra é {} de {}\".format(tamanho_amostra, tamanho_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine que desejemos ter uma aproximação da proporção de interações `normais` em nosso conjunto de dados. Poderíamos realizar a tarefa contando o número de instâncias com a palavra normal como anteriormente. \n",
    "\n",
    "Para uma resposta mais rápida, podemos fazer como a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A proporção de interações 'normais' é 0.199\n",
      "Contagem realizada em 7.949 segundos\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# transformações a serem aplicadas\n",
    "itens_amostra_rdd = amostra_rdd.map(lambda x: x.split(\",\"))\n",
    "itens_amostra_normais = itens_amostra_rdd.filter(lambda x: \"normal.\" in x)\n",
    "\n",
    "# ações + tempo\n",
    "t0 = time()\n",
    "contagem_itens_amostra_normais = itens_amostra_normais.count()\n",
    "tt = time() - t0\n",
    "\n",
    "razao_amostra_normal = contagem_itens_amostra_normais / float(tamanho_amostra)\n",
    "print(\"A proporção de interações 'normais' é {}\".format(round(razao_amostra_normal,3)) )\n",
    "print(\"Contagem realizada em {} segundos\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare com o cálculo da razão sem a amostragem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A proporção de interações 'normais' é 0.199\n",
      "Contagem realizada em 16.559 segundos\n"
     ]
    }
   ],
   "source": [
    "# transformações a serem aplicadas\n",
    "itens_rdd = rdd.map(lambda x: x.split(\",\"))\n",
    "itens_normais = itens_rdd.filter(lambda x: \"normal.\" in x)\n",
    "\n",
    "# ações + tempo\n",
    "t0 = time()\n",
    "contagem_itens_normais = itens_normais.count()\n",
    "tt = time() - t0\n",
    "\n",
    "razao_normal = contagem_itens_normais / float(tamanho_total)\n",
    "print(\"A proporção de interações 'normais' é {}\".format(round(razao_normal,3)) )\n",
    "print(\"Contagem realizada em {} segundos\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demora muito mais. Isso porque sem a amostragem todas as transformações são aplicadas ao conjunto completo de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A ação `takeSample`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos a ação `takeSample` para amostrar nosso RDD para ser utilizado por bibliotecas não-spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sintaxe é bem similar, mas neste caso especificamos o número de itens ao invés do tamanho da amostra como uma fração do conjunto completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A proporção das interações 'normais' é 0.1988025\n",
      "Contagem realizada em 14.542 segundos\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "amostra_rdd = rdd.takeSample(False, 400000, 1234)\n",
    "amostra_rdd_normal = [x.split(\",\") for x in amostra_rdd if \"normal.\" in x]\n",
    "tt = time() - t0\n",
    "\n",
    "tamanho_amostra_normal = len(amostra_rdd_normal)\n",
    "\n",
    "razao_normal = tamanho_amostra_normal / 400000.0\n",
    "print(\"A proporção das interações 'normais' é {}\".format(razao_normal))\n",
    "print(\"Contagem realizada em {} segundos\".format(round(tt,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O processo foi similar ao anterior. Obtivemos uma amostra de cerca de 10% dos dados, filtramos e aplicamos um split.\n",
    "\n",
    "No entanto, demorou mais, mesmo com uma amostra ligeiramente menor. Isso porque o Spark distribuiu a execução do processo de amostragem. A filtragem e o splitting dos resultados foram feitos localmente em um único nó."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
